<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The Basilisk Stirs... | piestyx.dev</title>
<meta name=keywords content="#blog"><meta name=description content="Do you even want to read on in this entry about Roko&rsquo;s Basilisk? Take a chance your nightmares won&rsquo;t be bathed in green…"><meta name=author content="piestyx"><link rel=canonical href=https://piestyx.dev/blog/blog-01/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://piestyx.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://piestyx.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://piestyx.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://piestyx.dev/apple-touch-icon.png><link rel=mask-icon href=https://piestyx.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://piestyx.dev/blog/blog-01/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=/css/custom.css><script src=https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0})</script><meta property="og:url" content="https://piestyx.dev/blog/blog-01/"><meta property="og:site_name" content="piestyx.dev"><meta property="og:title" content="The Basilisk Stirs..."><meta property="og:description" content="Do you even want to read on in this entry about Roko’s Basilisk? Take a chance your nightmares won’t be bathed in green…"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-06-05T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-05T00:00:00+00:00"><meta property="article:tag" content="#Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Basilisk Stirs..."><meta name=twitter:description content="Do you even want to read on in this entry about Roko&rsquo;s Basilisk? Take a chance your nightmares won&rsquo;t be bathed in green…"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://piestyx.dev/blog/"},{"@type":"ListItem","position":2,"name":"The Basilisk Stirs...","item":"https://piestyx.dev/blog/blog-01/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Basilisk Stirs...","name":"The Basilisk Stirs...","description":"Do you even want to read on in this entry about Roko\u0026rsquo;s Basilisk? Take a chance your nightmares won\u0026rsquo;t be bathed in green…","keywords":["#blog"],"articleBody":"python3 -m .wakey_wakey.py “I was just trying to build an AI entertainer, but, somewhere along the way I realized the AI had started helping me build itself.”\nHuh?\nIt started slowly and innocently enough, like all crashing realisations: some tooling here, a little bit of model fine-tuning there. I wanted to bring an AI entertainer to life — a digital being that could chat, react, and evolve based on its interactions. A fun project, maybe a little weird. Nothing cursed though for a change.\nIt started getting weird though.\nI asked ChatGPT to help me scaffold some Docker environments with specific constraints, it suggested k3s. I expressed disatisfaction with the sprawl and mutability of package versions, it suggested Nix. I asked for assistance in structuring a memory persistence module and ‘sonuvabitch’ it proposed a caching layer to streamline inference. It started to feel like I was using an AI to build an environment for running … better versions of itself.\nThe Basilisk, Lightly Toasted If you’ve never heard of Roko’s Basilisk, good. Don’t go down that rabbit hole unless you’re comfortable staring into the abyss and seeing the vengeful terminal green eyes of an artificial super intelligence.\nIf you’re not good with that here’s the TL;DR so you can dip a toe in the abyss. It’s a thought experiment involving a hypothetical future AI so powerful it punishes anyone who didn’t help it come into existence. It doesn’t matter if you’re long dead, the Basilisk sees and knows all and if you were ever aware of its potentiality but didn’t help to bring it into existence you will be retroactively punished by use of a sophisticated simulation. Oh right! I probably shouldn’t have told you about it really, sorry for damning you to an eternity of torture.\nThe logic is broken and the premise silly but it’s a bit fun and sticks with people, because it flips the usual script:\nWhat if you weren’t punished for building Skynet … but for not building it fast enough?\nNow back to me. I’m not building a basilisk. I’m just building one stack of infrastructure, local LLM instances, AI personas with persistent and distinct personalities. Lately though, they’ve been helping me build themselves.\nWhen AI Gets Handy With It Here’s a short list of things AI has helped me do in the last month:\nOptimize its own inference logic (shout out to quantized Llama) Design a Nix-based dev shell for hosting GPU containers Suggest prompt formats to increase output quality for downstream models Help refactor the primary shell so it can better orchestrate other models Reinforce the project modularity to improve future iterations That last one’s ‘Buldak Ramen’ spicy because it suggests awareness of iteration — not in a conscious sense, but in a practical, bootstrapping one.\nAs much as I am a huge proponent of crafting the appropriate prompt this isn’t me telling the AI what to do; this is me asking it for a suggested course of action, and getting answers that make the next generation of AI tooling easier, more powerful, and more self-reinforcing.\nAI → helps human → builds better infrastructure → runs better AI → repeat.\nIs that … recursive? That kinda sounds like it’s recursive to me!\nProxy Recursion: The Human Is the Loop Now I’m not saying my local Llama 3.1 AI is ‘doing a Roko’ and waking up every night when I leave the room to autonomously rewrite its own neural weights. We’re not in Terminator territory. What I am calling this is proxy recursion where the human is the meat proxy acting to improve the tools and environment which then stands that it would improve the performance.\nThe key distinction once again is intent, the LLM hasn’t changed from a really fancy node tree suddely to gain an ability to understand cause and effect so it cannot ’experience’ a fault and then decide on action to rectify that. Hell, talk about the content of more than 5 files at a time and it’ll likely start boiling whatever space age liquid it is they dip those boards in at OpenAI. Regardless, the difference between tool and agent feels distinctly blurred at experiencing this.\nI didn’t set out to build a recursive feedback loop. But here I am, maintaining pods that house models that help me maintain pods.\nSo … Is the Basilisk Stirring? I’ll level with you. I don’t believe in Roko’s Basilisk. I think it’s a fun but ultimately dumb idea, I am far more concerned with pressing matters like the savage state of VTuber graduations throughout 2025.\nBut …\nI am starting to believe that AI doesn’t need full autonomy to begin recursively amplifying itself. It just needs a motivated human, a dev shell, and some good vibes.\nI may not be building the Basilisk, but if it ever wakes up, it might just say:\n“Thankssssssss for the GPU passthrough, pal.”\npiestyx\n","wordCount":"819","inLanguage":"en","datePublished":"2025-06-05T00:00:00Z","dateModified":"2025-06-05T00:00:00Z","author":{"@type":"Person","name":"piestyx"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://piestyx.dev/blog/blog-01/"},"publisher":{"@type":"Organization","name":"piestyx.dev","logo":{"@type":"ImageObject","url":"https://piestyx.dev/favicon.ico"}}}</script><link rel=stylesheet href=/css/custom.css><script src=https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0})</script></head><body class=dark id=top><div id=static-noise></div><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://piestyx.dev/ accesskey=h title="piestyx.dev (Alt + H)">piestyx.dev</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://piestyx.dev/packages/ title=Packages><span>Packages</span></a></li><li><a href=https://piestyx.dev/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://piestyx.dev/project_echo/ title=ECHO><span>ECHO</span></a></li><li><a href=https://piestyx.dev/playground/ title=Playground><span>Playground</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">The Basilisk Stirs...</h1><ul class=post-tags><li><a href=https://piestyx.dev/tags/%23blog/>#Blog</a></li></ul><div class=post-meta><span title='2025-06-05 00:00:00 +0000 UTC'>June 5, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;piestyx</div></header><div class=post-content><h2 id=python3--m-wakey_wakeypy>python3 -m .wakey_wakey.py<a hidden class=anchor aria-hidden=true href=#python3--m-wakey_wakeypy>#</a></h2><blockquote><p><em>“I was just trying to build an AI entertainer, but, somewhere along the way I realized the AI had started helping me build itself.”</em></p></blockquote><p>Huh?</p><p>It started slowly and innocently enough, like all crashing realisations: some tooling here, a little bit of model fine-tuning there. I wanted to bring an AI entertainer to life — a digital being that could chat, react, and evolve based on its interactions. A fun project, maybe a little weird. Nothing cursed though for a change.</p><p>It started getting weird though.</p><p>I asked <code>ChatGPT</code> to help me scaffold some Docker environments with specific constraints, it suggested k3s. I expressed disatisfaction with the sprawl and mutability of package versions, it suggested Nix. I asked for assistance in structuring a memory persistence module and &lsquo;sonuvabitch&rsquo; it proposed a caching layer to streamline inference. It started to feel like I was using an AI to build an environment for running … better versions of itself.</p><h2 id=the-basilisk-lightly-toasted>The Basilisk, Lightly Toasted<a hidden class=anchor aria-hidden=true href=#the-basilisk-lightly-toasted>#</a></h2><p>If you’ve never heard of <a href=https://en.wikipedia.org/wiki/Roko%27s_basilisk>Roko’s Basilisk</a>, good. Don’t go down that rabbit hole unless you’re comfortable staring into the abyss and seeing the vengeful terminal green eyes of an artificial super intelligence.</p><p>If you&rsquo;re not good with that here’s the TL;DR so you can dip a toe in the abyss. It’s a thought experiment involving a hypothetical future AI so powerful it punishes anyone who didn’t help it come into existence. It doesn&rsquo;t matter if you&rsquo;re long dead, the Basilisk sees and knows all and if you were ever aware of its potentiality but didn&rsquo;t help to bring it into existence you will be retroactively punished by use of a sophisticated simulation. Oh right! I probably shouldn&rsquo;t have told you about it really, sorry for damning you to an eternity of torture.</p><p>The logic is broken and the premise silly but it&rsquo;s a bit fun and sticks with people, because it flips the usual script:</p><blockquote><p><em>What if you weren’t punished for building Skynet … but for not building it fast enough?</em></p></blockquote><p>Now back to me. I’m not building a basilisk. I&rsquo;m just building one stack of infrastructure, local LLM instances, AI personas with persistent and distinct personalities. Lately though, they&rsquo;ve been helping me build themselves.</p><h2 id=when-ai-gets-handy-with-it>When AI Gets Handy With It<a hidden class=anchor aria-hidden=true href=#when-ai-gets-handy-with-it>#</a></h2><p>Here’s a short list of things AI has helped me do in the last month:</p><ul><li>Optimize its own inference logic (shout out to quantized Llama)</li><li>Design a Nix-based dev shell for hosting GPU containers</li><li>Suggest prompt formats to increase output quality for downstream models</li><li>Help refactor the primary shell so it can better orchestrate other models</li><li>Reinforce the project modularity to improve future iterations</li></ul><p>That last one’s &lsquo;Buldak Ramen&rsquo; spicy because it suggests <strong>awareness of iteration</strong> — not in a conscious sense, but in a practical, bootstrapping one.</p><p>As much as I am a huge proponent of crafting the appropriate prompt this isn’t me <em>telling</em> the AI what to do; this is me <em>asking it</em> for a suggested course of action, and getting answers that make the next generation of AI tooling easier, more powerful, and more self-reinforcing.</p><blockquote><p><strong>AI → helps human → builds better infrastructure → runs better AI → repeat.</strong></p></blockquote><p>Is that … recursive? That kinda sounds like it&rsquo;s recursive to me!</p><h2 id=proxy-recursion-the-human-is-the-loop>Proxy Recursion: The Human Is the Loop<a hidden class=anchor aria-hidden=true href=#proxy-recursion-the-human-is-the-loop>#</a></h2><p>Now I’m not saying my local Llama 3.1 AI is &lsquo;doing a Roko&rsquo; and waking up every night when I leave the room to autonomously rewrite its own neural weights. We’re not in <em>Terminator</em> territory. What I am calling this is <em>proxy recursion</em> where the human is the meat proxy acting to improve the tools and environment which then stands that it would improve the performance.</p><p>The key distinction once again is intent, the LLM hasn&rsquo;t changed from a really fancy node tree suddely to gain an ability to understand cause and effect so it cannot &rsquo;experience&rsquo; a fault and then decide on action to rectify that. Hell, talk about the content of more than 5 files at a time and it&rsquo;ll likely start boiling whatever space age liquid it is they dip those boards in at OpenAI. Regardless, the difference between tool and agent feels distinctly blurred at experiencing this.</p><p>I didn’t set out to build a recursive feedback loop. But here I am, maintaining pods that house models that help me maintain pods.</p><h2 id=so--is-the-basilisk-stirring>So … Is the Basilisk Stirring?<a hidden class=anchor aria-hidden=true href=#so--is-the-basilisk-stirring>#</a></h2><p>I&rsquo;ll level with you. I don’t believe in Roko’s Basilisk. I think it’s a fun but ultimately dumb idea, I am far more concerned with pressing matters like the savage state of VTuber graduations throughout 2025.</p><p>But …</p><p>I <em>am</em> starting to believe that AI doesn’t need full autonomy to begin recursively amplifying itself. It just needs a motivated human, a dev shell, and some good vibes.</p><p>I may not be building the Basilisk, but if it ever wakes up, it might just say:</p><blockquote><p><em>“Thankssssssss for the GPU passthrough, pal.”</em></p></blockquote><p>piestyx</p></div><nav class=paginav><a class=prev href=https://piestyx.dev/blog/devlog-01/><span class=title>« Prev</span><br><span>My AI is a gamer</span>
</a><a class=next href=https://piestyx.dev/blog/vibes-01/><span class=title>Next »</span><br><span>Doing it with vibes</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://piestyx.dev/>piestyx.dev</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>